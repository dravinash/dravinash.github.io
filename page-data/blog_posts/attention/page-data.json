{"componentChunkName":"component---src-templates-post-js","path":"/blog_posts/attention","result":{"data":{"markdownRemark":{"html":"<h2>Overview</h2>\n<p>This article would discuss the following concepts</p>\n<blockquote>\n<ol>\n<li>Basic intuation of attention model</li>\n<li>Mathematics behind the attention model</li>\n<li>Implementation of attention mechanism</li>\n<li>Use of Tensorflow <code class=\"language-text\">tf.keras.layers.MultiHeadAttention</code> API</li>\n<li>Multi-Head Attention</li>\n</ol>\n</blockquote>\n<p>Without further delay, lets deep dive into what is attention mechanism, why it is so popular?</p>\n<h2>Basic intuation of attention model</h2>\n<p>Imagine you are reading a book, and you come across a character whose actions are essential to understand the current plot. To make sense of what's happening, you need to remember previous details about this character. Here’s how the attention mechanism works in this context: <br>\n<font color=#64ffda><strong>Query:</strong></font> Think of the query as the question you're asking while reading. For example, \"What has this character done before?\" <br>\n<font color=#64ffda><strong>Key:</strong></font> The key is like an index or a set of clues that help you find the right information in the book. It's the reference to different points in the story where this character is mentioned. <br>\n<font color=#64ffda><strong>Value:</strong></font> The value is the actual information you need about the character, like their past actions and traits.</p>\n<p>If we explain the same example in terms of python data types then it would be something similar to as described in the below example. The query is the question that we are looking for, key is the reference that can be <code class=\"language-text\">mahabharata_characters</code> and value would be the value of the query. So if we are looking for the character <code class=\"language-text\">Ashwatthama</code> then the <code class=\"language-text\">mahabharata_characters</code> would be the reference, treated as key and the value as <code class=\"language-text\">The formidable warrior and son of Dronacharya, known for his unrelenting pursuit of revenge against the Pandavas.</code>. <br></p>\n<div class=\"gatsby-code-title\">Dictionary.py</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># dictionary of characters and their description</span>\nmahabharata_characters <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"Arjuna\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"The peerless archer, whose valor and skill were unmatched on the battlefield of Kurukshetra\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"Krishna\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"The divine charioteer and guide to Arjuna, whose wisdom and counsel in the Bhagavad Gita are legendary.\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"Bhishma\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"The grand patriarch of the Kuru dynasty, renowned for his vow of celibacy and unparalleled warrior prowess.\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"Draupadi\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"The fiery princess and wife of the Pandavas, whose dignity and strength became a rallying point in their quest for justice.\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"Karna\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"The tragic hero and unparalleled warrior, known for his unwavering loyalty to Duryodhana and his inner conflict regarding his true lineage.\"</span>\n    <span class=\"token string\">\"Ashwatthama\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"The formidable warrior and son of Dronacharya, known for his unrelenting pursuit of revenge against the Pandavas.\"</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>Build upon this intuation, attention mechanism keeps the track of long sequences and give more weightsage to only certain portion who are useful for the token.</p>\n<h2>Mathematics behind the attention model</h2>\n<p>If we see the architecture proposed in the paper<sup id=\"fnref-1\"><a href=\"#fn-1\" class=\"footnote-ref\">1</a></sup>, it has the following component <code class=\"language-text\">Scale</code>, <code class=\"language-text\">Mask (Opt)</code>, <code class=\"language-text\">Softmax</code> and <code class=\"language-text\">matmul</code>. These are expressed in the hand written notes.\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 562px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/97fcca73755a96557680f3a08c26b760/eef63/attention-1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 53.714285714285715%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAABJ0AAASdAHeZh94AAAByUlEQVQoz3VTa0/iQBTl//+DdTfx8cFoIg/JCqsiSrHgCoIUfEBBUgp9EMqj25a+z2ZGqyhyksm5c3tzeubemZgsyxBFEZIkYSAMQPYkFgQBpmmCIAzD90WgqipGoxGtVRSF1mqaRr/FbNuGZVlwHBtB6MMPPIQIqJjneWuCZHmuB3WsotHkqNByuYTjOK+CeINtuSgXOWTSDBr1dpR+dxVxEASUJVnBef4Skzdn0c+ooOu5aLYfcJBM4Yq5wdMDT0rWjhoxgSI/osUlMB53sQoqOJ/PkL++wGkhi57A0+N/dRfFuq6j0+6hydVxfnaM+3oNPN/HUJSoeyo4Uye4O2Fwn2HBV1uYzmbf9o7ghm3hYK+A7a0Mtn9ksfMzi/h+CTu/ktC0CWJRYYPLocDsYqIp0PV/Gx12OwP8+c2iVukgdXSG2/IjLk4rKLFV+L736tCybDBXLFLxNHpdAYZhbBR87jzjMH6IfCGP+HECucscEukkiqXrjx4ahom/ZQ6lYgNdXoBhbhYUh0NUa3d46fdxW6lQJnuSp4JRoe+7dLJBGMBx3LWproov5nMaLxYLylNt+nnK312Lr/HqPSSPgTB5ECRPWhTdz/+EAzw32UT3cwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"attention 1\"\n        title=\"attention 1\"\n        src=\"/static/97fcca73755a96557680f3a08c26b760/eef63/attention-1.png\"\n        srcset=\"/static/97fcca73755a96557680f3a08c26b760/1aaec/attention-1.png 175w,\n/static/97fcca73755a96557680f3a08c26b760/98287/attention-1.png 350w,\n/static/97fcca73755a96557680f3a08c26b760/eef63/attention-1.png 562w\"\n        sizes=\"(max-width: 562px) 100vw, 562px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span>\nThe scaling or normalization is performed as if the value of dk become a large number, then the dot products grow large in magnitude, pushing the softmax function into regions where it has extremely small gradients. To counteract this effect, we scale the dot products by <code class=\"language-text\">1/sqrt(dk)</code> <sup id=\"fnref-1\"><a href=\"#fn-1\" class=\"footnote-ref\">1</a></sup>. The mask operation is optional, this one is used, in sequence to sequence generation or similar application. When the objective of the model is to predict the next token (word), and the input feature is the collection of previous words and the next word. If we want to mask the future token, in that situation we can use this masking operation. This sets the upper tringular matrix of the dot product between query and key to infinte and when we apply softmax on top of this, the upper tringular matrix is set to zero. This we do to make the sum equal to 1. For more reference, follow this video <sup id=\"fnref-2\"><a href=\"#fn-2\" class=\"footnote-ref\">2</a></sup>.\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 700px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/fe71b6a03016d0546283780acee4aeb2/9485b/attention-2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 140%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAcCAYAAABh2p9gAAAACXBIWXMAAAsTAAALEwEAmpwYAAADyElEQVRIx41W2ZajOgwUOwbMHiAECMlkpvux///nak6JONN9eu7yoOMFuVwuyTKS5zmWZcG6rqjrGtfrFbfbDWVZQkT+1TzPg+/7X/tJkmAYBrRtq4Dsn89n7RM0yzI1a61+a5rmNXZgRVEgjuNjoyAIUFUVjDGY51k/nk4nbTkexxF932vL09CPLdewjaJI/dI0PQBJlRN0eH9/1+M7QLZkTsY0sqI07JMtfdlyvWMrjjKdCEAN2XL3aZp0TFAaNyVA13XYtk3ByZ7rSewFyIU06vZfgfgfJmBgeBy2FJzBIEOOuTv7ZMh5GgNDtiThtCVz6qsaUlAOCMYPLhAE40KOaTwB5aA8BKUcHx8f6rPvOxhgZUgnasIFBCIwATjPzSg6T1DaEpfLBUVewKRG+wTmmv26I3SAjBAneYQwDDUVyJgtWfKY23VDc2phmxJVW2FeZ9RdjeW6oD21CNLwa1CoEVk4zbiBpsdpwM9fP7GeVyzJhEsyYi1mbPaC1q+w+BNG6TBIi06qA/CyLKjqGlVdqR5kRlZMDzJmPwoiGEmQi0HlWaSSIAsMMt+g8i3GuEfixQcgdWrLBnmaoy4P4U2SqmYu6ra0WLYFtrLoxx5VU2t/micM5xG3xw2FLQ5ALlzzGVMxYDYjispiyc6YsgFlXaJr21eKEJzydG2Hx+OhWcGAcuOXhtQstzlMbjQYdKIDo0kJGH3O86pxnidiS2CXcpqDDpDm8s4FIy+OwKgcz0pEEBdAtk5n+pP9C9CljSbxMOJ+vysQnd0R+Z1jAvMOk+22bqo3/VlDn/f5KI5d3yErMvSnHvtt10gzELYqYZ71zxUIMtVk3ncFJgmyfAHSYolQeBliL9J+ID5MZGDTApnJ9EaQHYGzPEdZlSjMIUsYh1+LAy2TFJUUmmuFZEglRimFzvVSoxaLWU7aZxJP0uMkjY5/yIrOq78C6tHFg5Vck5cbhBIgkhC+eNoPJIAvPjIxSL1E13BMH679Bmgk1WvUSY2LDMqExg12ueAuC1qpsMuMTc56kk9A3wH/8XUTD4nECOXQaknP+JFeNRO8Z1D/CsiFi4zKapUzRq/TozJID9mUNXW9pBPGpEcb1TiXI+I0+QqoJSuOYHOLIi0QBqHeEkZWK3qaIvQDreBJkGhAVm9C6AWIgxjiiabZ86F6Xr08R9M2WnHYZ1FlbjEt3JVjQWVurtOC+3pD27W47scjxgR/vs1/jsyr5x5y5hwdqJN7CrgRQcdpxLKt+gS8vb3p/F81/Pxb4eae78Q30wR/ForP334DwUZ+nbzkyk0AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"attention 2\"\n        title=\"attention 2\"\n        src=\"/static/fe71b6a03016d0546283780acee4aeb2/39600/attention-2.png\"\n        srcset=\"/static/fe71b6a03016d0546283780acee4aeb2/1aaec/attention-2.png 175w,\n/static/fe71b6a03016d0546283780acee4aeb2/98287/attention-2.png 350w,\n/static/fe71b6a03016d0546283780acee4aeb2/39600/attention-2.png 700w,\n/static/fe71b6a03016d0546283780acee4aeb2/57cd1/attention-2.png 1050w,\n/static/fe71b6a03016d0546283780acee4aeb2/9485b/attention-2.png 1155w\"\n        sizes=\"(max-width: 700px) 100vw, 700px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span>\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 700px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/f4923867f5990a11beb3746736fcf62a/2b633/attention-3.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 69.71428571428572%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAACFklEQVQ4y52UW0/cMBCFjy+xE9tJNlc2LF0QSlHbl1YqbUXLC///R51qYnYBib70YeJ4zvjzsTIOYAOhPaEDAcNt7hrClISNhO8I1xJFypqRsck531KVfa4DnsNGKp9YDHuqMGTRJqLaUTUTUUqMhEtEGKnnI3W/J7TjeveZ3+/v2XX9KyDAZUi8WRqmQZwV1ADjrqUeRupQEWXJUCdOU0eVaqKuWTeJj39+8+npiftl/wKMMXJd7/jp5shhatgMMy+miS7WdOOBSltq41k4x7Iqt0XetfTtyB+/fvLh8YHXh2ve4ooHzIQxhpeHA68WAWXrMQa2zUhfdCy0p0XJFBO7bkcFw1DsCGW5riu/ffnKu/qWH82Ro+nzkZ0raK0loM7Wu9hztPP2bqCpoRhDoDb2XJMQuOLIS0ycuo6mLDLwbWRoo2vOqmcJzxqRARXnYWIoK3q4LS+5AgVb1IyoqKHfA+YoAA5oaV65llDA9tHUP9YB2uYek77zu+f+6olyILTJedGLmqimPLo696q0k2hSr8zphJYI+ywKpJpzQbp6AcsmAhDQpncZLgZOG2l3AmoiXBBxyYUC325JyIWnkBshUAHW10T68Jwf8uYynoHibtuxJ8KSRTmKOEsHornNerwkqjEDxYDMZa04Nf7lpmyCuBSH4myLKh9H4FIszjbokjWBCFhcy9qzQ3mcfgLNzZte/J/4C7AnMzQPwW6EAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"attention 3\"\n        title=\"attention 3\"\n        src=\"/static/f4923867f5990a11beb3746736fcf62a/39600/attention-3.png\"\n        srcset=\"/static/f4923867f5990a11beb3746736fcf62a/1aaec/attention-3.png 175w,\n/static/f4923867f5990a11beb3746736fcf62a/98287/attention-3.png 350w,\n/static/f4923867f5990a11beb3746736fcf62a/39600/attention-3.png 700w,\n/static/f4923867f5990a11beb3746736fcf62a/57cd1/attention-3.png 1050w,\n/static/f4923867f5990a11beb3746736fcf62a/4af54/attention-3.png 1400w,\n/static/f4923867f5990a11beb3746736fcf62a/2b633/attention-3.png 1749w\"\n        sizes=\"(max-width: 700px) 100vw, 700px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h2>Implementation of attention mechanism</h2>\n<p>This section is the implementation of the above section in Tensorflow, I have taken reference from Professor Mubarak Shah Lecture, you can visit for more details <sup id=\"fnref-3\"><a href=\"#fn-3\" class=\"footnote-ref\">3</a></sup>.</p>\n<div class=\"gatsby-code-title\">attention_model.py</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">input_shape <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token number\">224</span><span class=\"token punctuation\">,</span> <span class=\"token number\">224</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># Assuming a 3-channel (RGB) image</span>\n\n<span class=\"token comment\"># Define the input layer</span>\ninputs <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span>input_shape<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Add a pre-trained ResNet50 layer (excluding the top classification layer)</span>\nresnet50_base <span class=\"token operator\">=</span> applications<span class=\"token punctuation\">.</span>ResNet50<span class=\"token punctuation\">(</span>include_top<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> weights<span class=\"token operator\">=</span><span class=\"token string\">'imagenet'</span><span class=\"token punctuation\">,</span> input_tensor<span class=\"token operator\">=</span>inputs<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># number of filters</span>\ndq <span class=\"token operator\">=</span> dk <span class=\"token operator\">=</span> dv <span class=\"token operator\">=</span><span class=\"token number\">3</span>\nfeature_dimension <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>resnet50_base<span class=\"token punctuation\">.</span>output_shape<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> resnet50_base<span class=\"token punctuation\">.</span>output_shape<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dk<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Output feature dimension:\"</span><span class=\"token punctuation\">,</span>feature_dimension<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Add a 1x1 convolutional layer to get the query</span>\nquery <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span>dq<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">\"query\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>resnet50_base<span class=\"token punctuation\">.</span>output<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Query output shape:\"</span><span class=\"token punctuation\">,</span> query<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Add a 1x1 convolutional layer to get the key</span>\nkey <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span>dk<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">\"key\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>resnet50_base<span class=\"token punctuation\">.</span>output<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Key output shape:\"</span><span class=\"token punctuation\">,</span> key<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Add a 1x1 convolutional layer to get the value</span>\nvalue <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span>dv<span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">\"value\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>resnet50_base<span class=\"token punctuation\">.</span>output<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Value output shape:\"</span><span class=\"token punctuation\">,</span> value<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Flatten the conv_layer to a 2D tensor</span>\nflattened_query <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Reshape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span>\nflattened_key <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Reshape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>key<span class=\"token punctuation\">)</span>\nflattened_value <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Reshape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>value<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Flattened Query shape:\"</span><span class=\"token punctuation\">,</span> flattened_query<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Flattened Key shape:\"</span><span class=\"token punctuation\">,</span> flattened_key<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Flattened Value shape:\"</span><span class=\"token punctuation\">,</span> flattened_value<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Transpose the flattened_key</span>\ntransposed_key <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Lambda<span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> tf<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> perm<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>flattened_key<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Print the shape of the transposed_key</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Transposed Key shape:\"</span><span class=\"token punctuation\">,</span> transposed_key<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Compute the dot product between the query and the key and scale it</span>\nscaled_prod <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Dot<span class=\"token punctuation\">(</span>axes<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>flattened_query<span class=\"token punctuation\">,</span> transposed_key<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> tf<span class=\"token punctuation\">.</span>math<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>dk<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Dot Product shape:\"</span><span class=\"token punctuation\">,</span> prod<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Apply softmax to the attention scores</span>\nsoftmax_layer <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Softmax<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>scaled_prod<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Softmax shape:\"</span><span class=\"token punctuation\">,</span> softmax_layer<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Compute the attention-weighted value</span>\nattention_output <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Dot<span class=\"token punctuation\">(</span>axes<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>softmax_layer<span class=\"token punctuation\">,</span> flattened_value<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Attention Output shape:\"</span><span class=\"token punctuation\">,</span> attention_output<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\nreshaped_attention_output <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Reshape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>feature_dimension<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>attention_output<span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\"># # Reshape the attention output to match the original image dimensions</span>\n<span class=\"token comment\"># reshaped_attention_output = layers.Reshape((32, 32, 3))(attention_output)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Reshaped Attention Output shape:\"</span><span class=\"token punctuation\">,</span> reshaped_attention_output<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Apply a 1x1 convolutional layer to the attention output</span>\nself_attended_feature <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">,</span> \n                                      name<span class=\"token operator\">=</span><span class=\"token string\">\"feature_map\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>reshaped_attention_output<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Self-attended Feature shape:\"</span><span class=\"token punctuation\">,</span> self_attended_feature<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Use of Tensorflow <code class=\"language-text\">tf.keras.layers.MultiHeadAttention</code> API</h2>\n<p>If you are using Tensoflow then, you may use <code class=\"language-text\">tf.keras.layers.MultiHeadAttention</code> this API to use the multihead attention directly. If <code class=\"language-text\">query</code>, <code class=\"language-text\">key</code>, <code class=\"language-text\">value</code> are the same, then this is self-attention <sup id=\"fnref-4\"><a href=\"#fn-4\" class=\"footnote-ref\">4</a></sup>. Each timestep in query attends to the corresponding sequence in <code class=\"language-text\">key</code>, and returns a fixed-width vector.</p>\n<p>This layer first projects <code class=\"language-text\">query</code>, <code class=\"language-text\">key</code> and <code class=\"language-text\">value</code>. These are (effectively) a list of tensors of length <code class=\"language-text\">num_attention_heads</code>, where the corresponding shapes are (<code class=\"language-text\">batch_size</code>, <code class=\"language-text\">&lt;query dimensions></code>, <code class=\"language-text\">key_dim</code>), (<code class=\"language-text\">batch_size</code>, <code class=\"language-text\">&lt;key/value dimensions></code>, <code class=\"language-text\">key_dim</code>), (<code class=\"language-text\">batch_size</code>, <code class=\"language-text\">&lt;key/value dimensions></code>, <code class=\"language-text\">value_dim</code>).</p>\n<p>Then, the query and key tensors are dot-producted and scaled. These are softmaxed to obtain attention probabilities. The value tensors are then interpolated by these probabilities, then concatenated back to a single tensor. Finally, the result tensor with the last dimension as value_dim can take a linear projection and return.</p>\n<div class=\"gatsby-code-title\">multihead_attention_model.py</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">self_attended_feature <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>MultiHeadAttention<span class=\"token punctuation\">(</span>num_heads<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> key_dim<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> value_dim <span class=\"token operator\">=</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>resnet50_base<span class=\"token punctuation\">.</span>output<span class=\"token punctuation\">,</span> resnet50_base<span class=\"token punctuation\">.</span>output<span class=\"token punctuation\">)</span></code></pre></div>\n<p>The comparison between both the models can be seen in the below figure.\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 700px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/0df7fd6cb7a86333f53b0b10f85f6633/faabe/attention-4.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 40%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABJ0AAASdAHeZh94AAABUUlEQVQoz1WRi46rMAxE+/9/2WopkAdJnBeUkLOCXt12LY1iWbJnMnOblcZYh/UR5Tw2WESElBLaaoZhYFIjr/3FWb13en+/0L9mb9zGaWZeMrVU5iD4FCilUtaCMjPTPCExsO87n+qfrne+66a0ZgmJlAtGhJACOWfWdcUYzf3nTqnlmmlj8SEhuV7EuWTqWnHeobRCknDT2mBdRGLBnArj++B5xFjNOI2EGBAJ3AeFcYlFIjY6Ss7ELDynJ/fHAxeWU6HB+kytFf1P4fnldVuxi+HnORBzukiUmrFpwQXPtu+04+DV2uXvaUlr7VSoL9ZcVmyM13Kple21YRbDY3hcarft9Z9o9Z4jCD3GC7T28XCaJkbjEYloHwhRSGfKUdBqYnw+kSh/QzkOemv0fX/jO2XnHD55pAo5JfpxcKTEESMtCMe2/Vm48CfnT9rn7Bc5Y2pOl41uTgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"attention 4\"\n        title=\"attention 4\"\n        src=\"/static/0df7fd6cb7a86333f53b0b10f85f6633/39600/attention-4.png\"\n        srcset=\"/static/0df7fd6cb7a86333f53b0b10f85f6633/1aaec/attention-4.png 175w,\n/static/0df7fd6cb7a86333f53b0b10f85f6633/98287/attention-4.png 350w,\n/static/0df7fd6cb7a86333f53b0b10f85f6633/39600/attention-4.png 700w,\n/static/0df7fd6cb7a86333f53b0b10f85f6633/57cd1/attention-4.png 1050w,\n/static/0df7fd6cb7a86333f53b0b10f85f6633/4af54/attention-4.png 1400w,\n/static/0df7fd6cb7a86333f53b0b10f85f6633/faabe/attention-4.png 1509w\"\n        sizes=\"(max-width: 700px) 100vw, 700px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h2>Multi Head Attention</h2>\n<p>When the number of head is one and the query, key and value dimensions are same then same network becomes self attention. But when we use multiple heads then the same network (key, query and value) gets multiplied with the number of heads and produce those many feature maps. Let's take the same example and extend it for the multiple heads.\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 700px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/b929cb787bd7bd2e4cba485ca31f1a71/799c6/attention-5.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 160.57142857142856%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAgCAYAAAASYli2AAAACXBIWXMAABJ0AAASdAHeZh94AAAEGklEQVRIx61WaXPrNgwEL92HJeqW7NhOHOfotJn2//+27RC06yj1e3nT6QcMbZEEFwsQSyIi/M92+aEUZLGBsg1k3UBuKqi2h8xLyLKCiBPITQ1lW4goBgWh3xcEEFnOc6TNzaGIIog4hcwLv6Cs+AD3X5Yb/qZsB1lZiDRjByKM/N4wgrgecHXoULlNIskYAW9I85uFER9wneP1cfLjkN0kn2gMIyKtGYlIUg5PzzuopuNvTEVWfMNhEEDW1jt2i01wCdeHrrrhytEvJkUIz4ULQxtG5pCqpmdkPlE1c8iJclynOc/dd/jFOFzmrYS0rUfZDp7bJPWRuDHNQFLeLxs1zv7UfvKZdKgcokvYjgY9baH68Z9ScRHo3fEzHVfP4naKkN6U9uVgAv7tvjEVRckU8Zo1Ou+Qw3MhXIqX+YliXyJcdznPueyqYeYEuqw75G7k0F2Bh6F3yNBdXUUx9LT4jU3HmZWuTFyIznlRQg0TpKvXrAQlBd8o0QygZoLc2EvILpwrB0EEUgGEC9NZlILiAiQIZCJQVDA90ggEZQHSEcJAIK8yqLTwDnVkoNMURBpKE8JNDjIxQknomwi5zaGDBMepwLyUCIsa27bEYciQ2ArLMOL92GDTW1AWBThODaalgslK7NoNnuYCeVNh7Ce8P+7xsLWww4zn4yPO+x7z4YCXl3ecH2aMuwG7wwmnwxbbnQu9afB6fsXTtkO3zHh+fsFv5yPa3qIfF7ycn7HfDrBdh+2yYGwrVHWFeZoxthZFnqFtW9RlibLIQUmS8MKhs0jTFMMwoKtrFEUObTSiKIRxN4cEwjBm/sTnEvtqQggoIb69o0IQlPLjt3dZ5AXUuMBGAw404ViF2LcCTdwjjregzSuKacH7K8Ha2+ZaCXRKoJJi7dDVW/D7X+jzPT7ohDeb4jwR5nxBFi4g+4F8OeDPD0LX3RxOWuIcKAz6y12WVQ1zfkebP+APOuG0SfG2ELq0RRz0jDC0C06P/3Z4ChSPYuXQtjDPb6jjAU+0YFeGmCyhjCxiXYGyLVSSYxoJcXxzOGuJp0DhwUioFYcmhIwzGBEgpxSZlkgDgqEIgYhAMoNRIapCr5KyaIm3QGGrJeTX9iVJQQoNVdTQVQ/dzDDNANPNCOc9dN2D7LDKaK8Eo9x/Rbgqj0unZqW7NtJLExVar9Y2SrDT5R7ClUnJneWTNN41IwijlkjEL0iA6zQs6D9xmDiURFyLriZj8VWkWEdCRuZkkpuq64v9yD2SG7CTBCcNTiGTFGFRItIahgjByqHWvlmyPode/aRireF+6XrjlWenju5wR4lbJ+6IlFvESPrRC/1FT2Tdcp06GXAH8ovhqnY/1eVLMtY8Gv9Q4udIdjMnB3XjNfmeSP0X4/JyLy6zfk38DQ7OuScJu3SNAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"attention 5\"\n        title=\"attention 5\"\n        src=\"/static/b929cb787bd7bd2e4cba485ca31f1a71/39600/attention-5.png\"\n        srcset=\"/static/b929cb787bd7bd2e4cba485ca31f1a71/1aaec/attention-5.png 175w,\n/static/b929cb787bd7bd2e4cba485ca31f1a71/98287/attention-5.png 350w,\n/static/b929cb787bd7bd2e4cba485ca31f1a71/39600/attention-5.png 700w,\n/static/b929cb787bd7bd2e4cba485ca31f1a71/799c6/attention-5.png 904w\"\n        sizes=\"(max-width: 700px) 100vw, 700px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h2>References</h2>\n<div class=\"footnotes\">\n<hr>\n<ol>\n<li id=\"fn-1\">Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... &#x26; Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing systems, 30.<a href=\"#fnref-1\" class=\"footnote-backref\">↩</a></li>\n<li id=\"fn-2\"><a href=\"https://www.youtube.com/watch?v=mmzRYGCfTzc\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.youtube.com/watch?v=mmzRYGCfTzc</a><a href=\"#fnref-2\" class=\"footnote-backref\">↩</a></li>\n<li id=\"fn-3\"><a href=\"https://www.youtube.com/watch?v=WyuZvGt7RY4&#x26;t=2207s\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.youtube.com/watch?v=WyuZvGt7RY4&#x26;t=2207s</a><a href=\"#fnref-3\" class=\"footnote-backref\">↩</a></li>\n<li id=\"fn-4\"><a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention</a><a href=\"#fnref-4\" class=\"footnote-backref\">↩</a></li>\n</ol>\n</div>","frontmatter":{"title":"Attention Please!","description":"Attention in machine learning is like the brain's spotlight, highlighting important parts of data. Introduced in 2014, it focuses on relevant information using \"queries,\" \"keys,\" and \"values.\" Imagine a model yelling, \"Hey, brain, remember that detail!\" to handle complex tasks like translating long sentences.","date":"2024-07-22","slug":"/blog_posts/attention","tags":["CNN","Attention","TensorFlow"]}}},"pageContext":{}},"staticQueryHashes":["3115057458"]}